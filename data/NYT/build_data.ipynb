{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83080f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples num: 56195\n",
      "Samples num: 61194\n",
      "Samples num: 66194\n",
      "Examples:  [{'sentText': 'Massachusetts ASTON MAGNA Great Barrington ; also at Bard College , Annandale-on-Hudson , N.Y. , July 1-Aug .', 'relationMentions': [{'em1Text': 'Annandale-on-Hudson', 'em2Text': 'College', 'label': '/location/location/contains'}]}, {'sentText': 'North Carolina EASTERN MUSIC FESTIVAL Greensboro , June 25-July 30 .', 'relationMentions': [{'em1Text': 'Carolina', 'em2Text': 'Greensboro', 'label': '/location/location/contains'}]}, {'sentText': \"It will be the final movie credited to Debra Hill , a film producer and native of Haddonfield , who produced '' Halloween '' and was considered a pioneering woman in film .\", 'relationMentions': [{'em1Text': 'Hill', 'em2Text': 'Haddonfield', 'label': '/people/person/place_of_birth'}]}]\n"
     ]
    }
   ],
   "source": [
    "# Get the samples.\n",
    "import json\n",
    "datas = []\n",
    "origin_file_list = [\"./origin_data/train.json\", \"./origin_data/valid.json\", \"./origin_data/test.json\"]\n",
    "for origin_file in origin_file_list:\n",
    "    with open(origin_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for index, line in enumerate(f):\n",
    "            line = json.loads(line.strip())\n",
    "            datas.append(line)\n",
    "    print(\"Samples num: {}\".format(len(datas)))\n",
    "print(\"Examples: \", datas[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63f5b373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation_types_list:  ['/business/company/place_founded', '/people/deceased_person/place_of_death', '/location/neighborhood/neighborhood_of', '/location/administrative_division/country', '/location/location/contains', '/business/company/founders', '/people/person/children', '/people/person/profession', '/people/ethnicity/geographic_distribution', '/sports/sports_team/location', '/people/person/place_of_birth', '/location/country/administrative_divisions', '/business/company/industry', '/business/company/major_shareholders', '/people/ethnicity/people', '/location/country/capital', '/sports/sports_team_location/teams', '/business/company/advisors', '/people/person/nationality', '/people/person/religion', '/people/person/ethnicity', '/business/person/company', '/business/company_shareholder/major_shareholder_of', '/people/person/place_lived']\n",
      "length:  24\n"
     ]
    }
   ],
   "source": [
    "# Get the relations.\n",
    "relation_types_list = set()\n",
    "for data in datas:\n",
    "    for relation in data[\"relationMentions\"]:\n",
    "        relation_types_list.add(relation[\"label\"])\n",
    "relation_types_list = list(relation_types_list)\n",
    "print(\"relation_types_list: \", relation_types_list)\n",
    "print(\"length: \", len(relation_types_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17ae3212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'business': ['/business/company/place_founded', '/business/company/founders', '/business/company/industry', '/business/company/major_shareholders', '/business/company/advisors', '/business/person/company', '/business/company_shareholder/major_shareholder_of'], 'people': ['/people/deceased_person/place_of_death', '/people/person/children', '/people/person/profession', '/people/ethnicity/geographic_distribution', '/people/person/place_of_birth', '/people/ethnicity/people', '/people/person/nationality', '/people/person/religion', '/people/person/ethnicity', '/people/person/place_lived'], 'sports': ['/sports/sports_team/location', '/sports/sports_team_location/teams'], 'location': ['/location/neighborhood/neighborhood_of', '/location/administrative_division/country', '/location/location/contains', '/location/country/administrative_divisions', '/location/country/capital']}\n",
      "{'business': 7, 'people': 10, 'sports': 2, 'location': 5}\n"
     ]
    }
   ],
   "source": [
    "relation_dict = {\n",
    "    \"business\": [],\n",
    "    \"people\": [],\n",
    "    \"sports\": [],\n",
    "    \"location\": []\n",
    "}\n",
    "relation_dict_len = {\n",
    "    \"business\": 0,\n",
    "    \"people\": 0,\n",
    "    \"sports\": 0,\n",
    "    \"location\": 0\n",
    "}\n",
    "for relation in relation_types_list:\n",
    "    relation_dict[relation.split(\"/\")[1]].append(relation)\n",
    "    relation_dict_len[relation.split(\"/\")[1]] += 1\n",
    "print(relation_dict)\n",
    "print(relation_dict_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d10db82",
   "metadata": {},
   "source": [
    "### Splite the relation types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "926a89de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intra_train: ['/location/neighborhood/neighborhood_of', '/location/administrative_division/country', '/location/location/contains', '/location/country/administrative_divisions', '/location/country/capital', '/sports/sports_team/location', '/sports/sports_team_location/teams'], len: 7\n",
      "intra_dev: ['/business/company/place_founded', '/business/company/founders', '/business/company/industry', '/business/company/major_shareholders', '/business/company/advisors', '/business/person/company', '/business/company_shareholder/major_shareholder_of'], len: 7\n",
      "intra_test: ['/people/deceased_person/place_of_death', '/people/person/children', '/people/person/profession', '/people/ethnicity/geographic_distribution', '/people/person/place_of_birth', '/people/ethnicity/people', '/people/person/nationality', '/people/person/religion', '/people/person/ethnicity', '/people/person/place_lived'], len: 10\n"
     ]
    }
   ],
   "source": [
    "# for Intra\n",
    "intra_train_types_list = relation_dict[\"location\"] + relation_dict[\"sports\"]\n",
    "intra_dev_types_list = relation_dict[\"business\"]\n",
    "intra_test_types_list = relation_dict[\"people\"]\n",
    "print(\"intra_train: {}, len: {}\".format(intra_train_types_list, len(intra_train_types_list)))\n",
    "print(\"intra_dev: {}, len: {}\".format(intra_dev_types_list, len(intra_dev_types_list)))\n",
    "print(\"intra_test: {}, len: {}\".format(intra_test_types_list, len(intra_test_types_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efd29231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inter_train: ['/business/company/place_founded', '/people/deceased_person/place_of_death', '/location/neighborhood/neighborhood_of', '/location/administrative_division/country', '/location/location/contains', '/business/company/founders', '/people/person/children', '/people/person/profession', '/people/ethnicity/geographic_distribution', '/sports/sports_team/location', '/people/person/place_of_birth', '/location/country/administrative_divisions', '/business/company/industry', '/business/company/major_shareholders'], len: 14\n",
      "inter_dev: ['/people/ethnicity/people', '/location/country/capital', '/sports/sports_team_location/teams', '/business/company/advisors', '/people/person/nationality'], len: 5\n",
      "inter_test: ['/people/person/religion', '/people/person/ethnicity', '/business/person/company', '/business/company_shareholder/major_shareholder_of', '/people/person/place_lived'], len: 5\n"
     ]
    }
   ],
   "source": [
    "# for Inter\n",
    "import random\n",
    "random.seed(7)\n",
    "order = [i for i in range(24)]\n",
    "random.shuffle(order)\n",
    "inter_train_types_list = relation_types_list[0:14]\n",
    "inter_dev_types_list = relation_types_list[14:19]\n",
    "inter_test_types_list = relation_types_list[19:24]\n",
    "print(\"inter_train: {}, len: {}\".format(inter_train_types_list, len(inter_train_types_list)))\n",
    "print(\"inter_dev: {}, len: {}\".format(inter_dev_types_list, len(inter_dev_types_list)))\n",
    "print(\"inter_test: {}, len: {}\".format(inter_test_types_list, len(inter_test_types_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c4deeb",
   "metadata": {},
   "source": [
    "### Splite the samples based on the relation types list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ee62df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'sentText': 'Massachusetts ASTON MAGNA Great Barrington ; also at Bard College , Annandale-on-Hudson , N.Y. , July 1-Aug .', 'relationMentions': [{'em1Text': 'Annandale-on-Hudson', 'em2Text': 'College', 'label': '/location/location/contains'}]}, {'sentText': 'North Carolina EASTERN MUSIC FESTIVAL Greensboro , June 25-July 30 .', 'relationMentions': [{'em1Text': 'Carolina', 'em2Text': 'Greensboro', 'label': '/location/location/contains'}]}]\n",
      "[{'sentText': 'Massachusetts ASTON MAGNA Great Barrington ; also at Bard College , Annandale-on-Hudson , N.Y. , July 1-Aug .', 'relationMentions': [{'em1Text': 'Annandale-on-Hudson', 'em2Text': 'College', 'label': '/location/location/contains'}]}, {'sentText': 'North Carolina EASTERN MUSIC FESTIVAL Greensboro , June 25-July 30 .', 'relationMentions': [{'em1Text': 'Carolina', 'em2Text': 'Greensboro', 'label': '/location/location/contains'}]}]\n",
      "Train: 45451, Dev: 6082, Test: 16711.\n"
     ]
    }
   ],
   "source": [
    "# Intra data\n",
    "import copy\n",
    "intra_types_list = [intra_train_types_list, intra_dev_types_list, intra_test_types_list]\n",
    "intra_datas = [[] for i in range(3)] # Train, Dev, Test\n",
    "for data in datas:\n",
    "    for i in range(3):\n",
    "        for relation in data[\"relationMentions\"]:\n",
    "            if relation[\"label\"] in intra_types_list[i]:\n",
    "                intra_datas[i].append(copy.copy(data))\n",
    "                break\n",
    "print(intra_datas[0][0:2])\n",
    "for i in range(3):\n",
    "    for intra_data in intra_datas[i]:\n",
    "        intraRelationMentions = []\n",
    "        for relation in intra_data[\"relationMentions\"]:\n",
    "            if relation[\"label\"] in intra_types_list[i]:\n",
    "                intraRelationMentions.append(relation)\n",
    "        assert len(intraRelationMentions) != 0\n",
    "        intra_data[\"relationMentions\"] = intraRelationMentions\n",
    "print(intra_datas[0][0:2])\n",
    "print(\"Train: {}, Dev: {}, Test: {}.\".format(len(intra_datas[0]), len(intra_datas[1]), len(intra_datas[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7033e541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save intra data\n",
    "import os\n",
    "import json\n",
    "if not os.path.exists(\"intra_data\"):\n",
    "    os.mkdir(\"intra_data\")\n",
    "intra_file_names = [\"./intra_data/train.json\", \"./intra_data/dev.json\", \"./intra_data/test.json\"]\n",
    "for index, file_name in enumerate(intra_file_names):\n",
    "    with open(file_name, \"w\", encoding=\"utf-8\") as f:\n",
    "        for intra_data in intra_datas[index]:\n",
    "            write_str = json.dumps(intra_data) + \"\\n\"\n",
    "            f.write(write_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d1c394b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'sentText': 'Massachusetts ASTON MAGNA Great Barrington ; also at Bard College , Annandale-on-Hudson , N.Y. , July 1-Aug .', 'relationMentions': [{'em1Text': 'Annandale-on-Hudson', 'em2Text': 'College', 'label': '/location/location/contains'}]}, {'sentText': 'North Carolina EASTERN MUSIC FESTIVAL Greensboro , June 25-July 30 .', 'relationMentions': [{'em1Text': 'Carolina', 'em2Text': 'Greensboro', 'label': '/location/location/contains'}]}]\n",
      "[{'sentText': 'Massachusetts ASTON MAGNA Great Barrington ; also at Bard College , Annandale-on-Hudson , N.Y. , July 1-Aug .', 'relationMentions': [{'em1Text': 'Annandale-on-Hudson', 'em2Text': 'College', 'label': '/location/location/contains'}]}, {'sentText': 'North Carolina EASTERN MUSIC FESTIVAL Greensboro , June 25-July 30 .', 'relationMentions': [{'em1Text': 'Carolina', 'em2Text': 'Greensboro', 'label': '/location/location/contains'}]}]\n",
      "Train: 50543, Dev: 14362, Test: 12284.\n"
     ]
    }
   ],
   "source": [
    "# Inter data\n",
    "import copy\n",
    "inter_types_list = [inter_train_types_list, inter_dev_types_list, inter_test_types_list]\n",
    "inter_datas = [[] for i in range(3)] # Train, Dev, Test\n",
    "for data in datas:\n",
    "    for i in range(3):\n",
    "        for relation in data[\"relationMentions\"]:\n",
    "            if relation[\"label\"] in inter_types_list[i]:\n",
    "                inter_datas[i].append(copy.copy(data))\n",
    "                break\n",
    "print(inter_datas[0][0:2])\n",
    "for i in range(3):\n",
    "    for inter_data in inter_datas[i]:\n",
    "        interRelationMentions = []\n",
    "        for relation in inter_data[\"relationMentions\"]:\n",
    "            if relation[\"label\"] in inter_types_list[i]:\n",
    "                interRelationMentions.append(relation)\n",
    "        assert len(interRelationMentions) != 0\n",
    "        inter_data[\"relationMentions\"] = interRelationMentions\n",
    "print(inter_datas[0][0:2])\n",
    "print(\"Train: {}, Dev: {}, Test: {}.\".format(len(inter_datas[0]), len(inter_datas[1]), len(inter_datas[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab2e46df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save inter data\n",
    "import os\n",
    "import json\n",
    "if not os.path.exists(\"inter_data\"):\n",
    "    os.mkdir(\"inter_data\")\n",
    "inter_file_names = [\"./inter_data/train.json\", \"./inter_data/dev.json\", \"./inter_data/test.json\"]\n",
    "for index, file_name in enumerate(inter_file_names):\n",
    "    with open(file_name, \"w\", encoding=\"utf-8\") as f:\n",
    "        for inter_data in inter_datas[index]:\n",
    "            write_str = json.dumps(inter_data) + \"\\n\"\n",
    "            f.write(write_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0cfb77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
